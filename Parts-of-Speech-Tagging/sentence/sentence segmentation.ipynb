{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f2c02c",
   "metadata": {},
   "source": [
    "# Sentence Segmentation\n",
    "In **spaCy Basics** we saw briefly how Doc objects are divided into sentences. In this section we'll learn how sentence segmentation works, and how to set our own segmentation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2143dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load(u\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f66d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"This is the first sentence. This is another sentence. This is the last sentence.\")\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d11c5",
   "metadata": {},
   "source": [
    "### `Doc.sents` is a generator\n",
    "It is important to note that `doc.sents` is a *generator*. That is, a Doc is not segmented until `doc.sents` is called. This means that, where you could print the second Doc token with `print(doc[1])`, you can't call the \"second Doc sentence\" with `print(doc.sents[1])`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8391b73d",
   "metadata": {},
   "source": [
    "However, you *can* build a sentence collection by running `doc.sents` and saving the result to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf63df41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is the first sentence.,\n",
       " This is another sentence.,\n",
       " This is the last sentence.]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents = [doc for doc in doc.sents]\n",
    "doc_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53447eb8",
   "metadata": {},
   "source": [
    "<font color=green>**NOTE**: `list(doc.sents)` also works. We show a list comprehension as it allows you to pass in conditionals.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e7169f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is another sentence."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af83bda",
   "metadata": {},
   "source": [
    "### `sents` are Spans\n",
    "At first glance it looks like each `sent` contains text from the original Doc object. In fact they're just Spans with start and end token pointers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138fbd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b7feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 11\n"
     ]
    }
   ],
   "source": [
    "print(doc_sents[1].start, doc_sents[1].end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f028c21",
   "metadata": {},
   "source": [
    "Let's add a semicolon to our existing segmentation rules. That is, whenever the sentencizer encounters a semicolon, the next token should start a new segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916c337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPACY'S DEFAULT BEHAVIOR\n",
    "doc = nlp(u'\"Management is doing the right thing; leadership is doing the right things.\" -Peter drucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "343bec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Management is doing the right thing; leadership is doing the right things.\" -Peter drucker'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb0be44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing the right thing; leadership is doing the right things.\"\n",
      "\n",
      "\n",
      "-Peter drucker\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2087394",
   "metadata": {},
   "source": [
    "## Adding Rules\n",
    "spaCy's built-in `sentencizer` relies on the dependency parse and end-of-sentence punctuation to determine segmentation rules. We can add rules of our own, but they have to be added *before* the creation of the Doc object, as that is where the parsing of segment start tokens happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b2bf474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "750097f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'set_custom_boundaries',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD A SEGMENTATION RULE\n",
    "@Language.component('set_custom_boundaries')\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe('set_custom_boundaries', before='parser')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017eb1d",
   "metadata": {},
   "source": [
    "<font color=green>The new rule has to run before the document is parsed. Here we can either pass the argument `before='parser'` or `first=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "341c54e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing the right thing;\n",
      "leadership is doing the right things.\"\n",
      "-Peter drucker\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u'\"Management is doing the right thing; leadership is doing the right things.\" -Peter drucker')\n",
    "\n",
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1dacb",
   "metadata": {},
   "source": [
    "## Changing the Rules\n",
    "In some cases we want to *replace* spaCy's default sentencizer with our own set of rules. In this section we'll see how the default sentencizer breaks on periods. We'll then replace this behavior with a sentencizer that breaks on linebreaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa5752bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.']\n",
      "['This', 'is', 'another', '.', '\\n\\n']\n",
      "['This', 'is', 'a', '\\n', 'third', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')  # reset to the original\n",
    "\n",
    "mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\"\n",
    "\n",
    "# SPACY DEFAULT BEHAVIOR:\n",
    "doc = nlp(mystring)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "951c15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27306b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.split_on_newlines(doc)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHANGE SEGMENTATION RULES\n",
    "@Language.component('split_on_newlines')\n",
    "def split_on_newlines(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == '\\n':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "        elif token.text == '.':\n",
    "            doc[token.i+1].is_sent_start = False\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe('split_on_newlines', before='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfb5f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.']\n",
      "['This', 'is', 'another', '.', '\\n\\n']\n",
      "['This', 'is', 'a', '\\n']\n",
      "['third', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(mystring)\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "506f3f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another.\n",
      "\n",
      "\n",
      "This is a \n",
      "\n",
      "third sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
